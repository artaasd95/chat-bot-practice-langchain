# LangGraph Chat System

A comprehensive AI-powered chat system built with modern microservices architecture, featuring LangGraph, FastAPI, and a beautiful Vue.js frontend. The system provides enterprise-grade chat capabilities with advanced AI integration, user management, and administrative controls.

## ðŸš€ Demo & Screenshots

### User Interface Overview

Our chat system features a modern, responsive web interface built with Vue.js and Tailwind CSS:

#### ðŸ” Authentication & Login
![Login Panel](./images/login-panel.png)
*Secure authentication system with JWT tokens and role-based access control*

#### ðŸ“Š Dashboard
![Dashboard](./images/dashboard.png)
*Comprehensive dashboard with system statistics, user activity, and quick access to all features*

#### ðŸ’¬ Chat Interface
![Chat Interface](./images/chat.png)
*Intuitive chat interface with real-time messaging, conversation history, and AI-powered responses*

#### âš™ï¸ Admin Panel
![Admin Panel](./images/admin.png)
*Powerful administrative interface for user management, system monitoring, and configuration*

### Live Demo

ðŸŒ **Try the live demo**: [Coming Soon]

ðŸ“– **API Documentation**: Available at `/docs` when running locally

## âœ¨ Features

### ðŸŽ¯ Core Features

#### **AI & Chat Capabilities**
- ðŸ¤– **Multiple LLM Providers**: Support for OpenAI, DeepSeek, and other AI providers
- ðŸ§  **Enhanced Graph Architecture**: Advanced conversation flow with LangGraph
- ðŸ”— **REST API Tools**: AI can make external API calls during conversations
- ðŸ’¾ **Conversation History**: Persistent chat sessions with context management
- âš¡ **Real-time Messaging**: WebSocket support for instant communication
- ðŸŽ›ï¸ **Conversation Management**: Create, organize, and manage multiple chat sessions

#### **User Management & Authentication**
- ðŸ” **JWT Authentication**: Secure token-based authentication system
- ðŸ‘¥ **Role-Based Access Control**: User and admin roles with different permissions
- ðŸ“ **User Registration**: Self-service user registration with email validation
- ðŸ”‘ **Password Management**: Secure password change and reset functionality
- ðŸ‘¤ **Profile Management**: User profiles with customizable information

#### **Administrative Features**
- ðŸ“Š **System Dashboard**: Comprehensive system statistics and monitoring
- ðŸ‘¨â€ðŸ’¼ **User Management**: Admin panel for managing users and permissions
- ðŸ“ˆ **Analytics**: User activity tracking and system performance metrics
- âš™ï¸ **System Configuration**: Configurable settings and system parameters
- ðŸ—‚ï¸ **Data Export**: Export user data and chat histories

### ðŸ—ï¸ Architecture Features

#### **Microservices Architecture**
- ðŸ”§ **Service Separation**: Dedicated services for auth, chat, admin, and frontend
- ðŸ³ **Docker Containerization**: Full Docker support with docker-compose
- ðŸŒ **API Gateway**: Nginx-based API gateway with load balancing
- ðŸ“¡ **Service Communication**: RESTful APIs between services
- ðŸ”„ **Scalable Design**: Horizontal scaling support

#### **Database & Storage**
- ðŸ—„ï¸ **PostgreSQL**: Robust relational database for data persistence
- ðŸš€ **Redis**: Caching and session management
- ðŸ“Š **Database Migrations**: Automated database schema management
- ðŸ’¾ **Data Backup**: Automated backup and recovery procedures

#### **Development & Operations**
- ðŸ” **Comprehensive Logging**: Structured logging with rotation policies
- ðŸ“Š **Monitoring**: Prometheus and Grafana integration
- ðŸ§ª **Testing**: Comprehensive test suite with pytest
- ðŸš€ **CI/CD Ready**: GitHub Actions and deployment automation
- ðŸ“– **Documentation**: Extensive documentation and API references

### ðŸŽ¨ Frontend Features

#### **Modern UI/UX**
- ðŸŽ¨ **Responsive Design**: Mobile-first responsive interface
- ðŸŒ™ **Dark/Light Mode**: Theme switching support
- âš¡ **Fast Performance**: Optimized Vue.js application with Vite
- ðŸŽ¯ **Intuitive Navigation**: User-friendly interface design
- ðŸ“± **Mobile Support**: Full mobile device compatibility

#### **Interactive Components**
- ðŸ’¬ **Real-time Chat**: Live chat with typing indicators
- ðŸ”” **Notifications**: Toast notifications for user feedback
- ðŸ“‹ **Data Tables**: Advanced tables with sorting and filtering
- ðŸ“Š **Charts & Graphs**: Visual data representation
- ðŸ” **Search & Filter**: Advanced search capabilities

### ðŸ”§ Technical Features

#### **API & Integration**
- ðŸŒ **RESTful APIs**: Well-documented REST endpoints
- ðŸ“¡ **WebSocket Support**: Real-time bidirectional communication
- ðŸ”Œ **Webhook Support**: External system integration
- ðŸ“‹ **OpenAPI/Swagger**: Auto-generated API documentation
- ðŸ”„ **CORS Support**: Cross-origin resource sharing

#### **Security & Performance**
- ðŸ›¡ï¸ **Security Headers**: Comprehensive security configurations
- ðŸš¦ **Rate Limiting**: API rate limiting and abuse prevention
- âš¡ **Async Processing**: Fully asynchronous implementation
- ðŸ—œï¸ **Response Compression**: Gzip compression for optimal performance
- ðŸ”’ **Data Encryption**: Secure data handling and storage

## Project Structure

```
.
â”œâ”€â”€ app/                    # Main application package
â”‚   â”œâ”€â”€ __init__.py        # Package initialization
â”‚   â”œâ”€â”€ main.py            # FastAPI application entry point
â”‚   â”œâ”€â”€ config.py          # Configuration management
â”‚   â”œâ”€â”€ api/               # API endpoints and models
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ models.py      # Pydantic models for requests/responses
â”‚   â”‚   â””â”€â”€ routes.py      # API route definitions
â”‚   â”œâ”€â”€ database/          # Database models and operations
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ models.py      # SQLAlchemy database models
â”‚   â”‚   â””â”€â”€ session.py     # Database session management
â”‚   â”œâ”€â”€ graph/             # LangGraph implementation
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ builder.py     # Graph construction (basic, advanced, enhanced)
â”‚   â”‚   â””â”€â”€ nodes.py       # Graph node implementations
â”‚   â”œâ”€â”€ services/          # Core services
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ api_tools.py   # API tools service for external calls
â”‚   â”‚   â”œâ”€â”€ history.py     # Conversation history service
â”‚   â”‚   â”œâ”€â”€ llm.py         # LLM service
â”‚   â”‚   â””â”€â”€ webhook.py     # Webhook service
â”‚   â””â”€â”€ utils/             # Utility modules
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ logging.py     # Logging configuration
â”‚       â”œâ”€â”€ monitoring.py  # Monitoring and LangSmith integration
â”‚       â””â”€â”€ tracking.py    # Request tracking utilities
â”œâ”€â”€ docs/                  # Documentation
â”‚   â”œâ”€â”€ api/              # API documentation
â”‚   â”‚   â””â”€â”€ chat-api.md   # Chat API endpoints and models
â”‚   â”œâ”€â”€ ai/               # AI/LangGraph documentation
â”‚   â”‚   â”œâ”€â”€ langgraph-architecture.md  # Graph architecture guide
â”‚   â”‚   â”œâ”€â”€ langsmith-integration.md   # LangSmith integration guide
â”‚   â”‚   â””â”€â”€ deepseek-integration.md    # DeepSeek integration guide
â”‚   â”œâ”€â”€ backend/          # Backend documentation
â”‚   â”‚   â”œâ”€â”€ architecture.md  # System architecture
â”‚   â”‚   â””â”€â”€ services.md   # Services documentation
â”‚   â””â”€â”€ database/         # Database documentation
â”‚       â””â”€â”€ schema.md     # Database schema and models
â”œâ”€â”€ tests/                # Test files
â”‚   â”œâ”€â”€ test_enhanced_graph.py     # Enhanced graph tests
â”‚   â”œâ”€â”€ test_deepseek_integration.py # DeepSeek integration tests
â”‚   â””â”€â”€ ...               # Other test modules organized by feature
â”œâ”€â”€ requirements.txt      # Consolidated project dependencies
â””â”€â”€ requirements-test.txt # Testing dependencies
```

## Setup

### Prerequisites

- Python 3.9+
- OpenAI API key OR DeepSeek API key (or other LLM provider)

### Installation

1. Clone the repository:
   ```bash
   git clone https://github.com/artaasd95/chat-bot-practice-langchain.git
   cd chat-bot-practice-langchain
   ```

2. Create a virtual environment:
   ```bash
   python -m venv venv
   # On Windows
   .\venv\Scripts\activate
   # On Unix/MacOS
   source venv/bin/activate
   ```

3. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```

4. Create a `.env` file in the project root with your configuration:
   ```
   # API Settings
   API_HOST=0.0.0.0
   API_PORT=8000
   API_WORKERS=4
   
   # CORS Settings
   CORS_ALLOW_ORIGINS=http://localhost:3000,http://localhost:8080
   
   # LLM Settings - Choose your provider
   LLM_PROVIDER=openai  # or "deepseek" for DeepSeek API
   LLM_MODEL=gpt-3.5-turbo  # or "deepseek-chat" for DeepSeek
   LLM_TEMPERATURE=0.7
   LLM_MAX_TOKENS=1000
   
   # OpenAI Configuration
   OPENAI_API_KEY=your_openai_api_key
   
   # DeepSeek Configuration (alternative to OpenAI)
   DEEPSEEK_API_KEY=your_deepseek_api_key
   
   # Logging Settings
   LOG_LEVEL=INFO
   LOG_RETENTION=7 days
   LOG_ROTATION=100 MB
   
   # Webhook Settings
   WEBHOOK_MAX_RETRIES=3
   WEBHOOK_RETRY_DELAY=2
   ```

### Running the Application

#### Development

```bash
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

#### Production

```bash
gunicorn app.main:app -k uvicorn.workers.UvicornWorker -w 4 --bind 0.0.0.0:8000
```

## API Usage

### Health Check

```bash
curl http://localhost:8000/health
```

### Enhanced Chat (Recommended)

The enhanced chat endpoint provides full conversation history and API tool calling capabilities:

```bash
curl -X POST http://localhost:8000/api/chat \
  -H "Content-Type: application/json" \
  -d '{
    "messages": [{"role": "user", "content": "Hello, how are you?"}],
    "conversation_id": "optional-session-id"
  }'
```

Response includes enhanced metadata:
```json
{
  "response": "Hello! I'm doing well, thank you for asking.",
  "request_id": "req_123456",
  "conversation_id": "conv_789",
  "metadata": {
    "api_calls_made": 0,
    "history_loaded": true,
    "messages_in_context": 5,
    "api_call_details": null
  }
}
```

### Direct Chat (Legacy)

```bash
curl -X POST http://localhost:8000/api/chat/direct \
  -H "Content-Type: application/json" \
  -d '{"messages": [{"role": "user", "content": "Hello, how are you?"}]}'
```

### Webhook Chat

```bash
curl -X POST http://localhost:8000/api/chat/webhook \
  -H "Content-Type: application/json" \
  -d '{
    "messages": [{"role": "user", "content": "Tell me about LangGraph"}],
    "callback_url": "https://your-callback-url.com/webhook"
  }'
```

### Check Webhook Status

```bash
curl http://localhost:8000/api/chat/webhook/status/{track_id}
```

## Enhanced Graph Features

### API Tool Calling

The enhanced graph can automatically detect when the LLM wants to make external API calls and execute them:

```python
# Example conversation that triggers API call
user_message = "Get the current weather in New York"
# LLM response: "API_CALL: GET https://api.weather.com/v1/current?location=New+York"
# System automatically makes the API call and incorporates the response
```

### Conversation History

Conversations are automatically saved and loaded:

- **Automatic Loading**: Previous messages are loaded when a `conversation_id` is provided
- **Context Management**: The system maintains conversation context across sessions
- **Persistent Storage**: All conversations are stored in PostgreSQL database

### Graph Types

1. **Basic Graph**: Simple linear flow for standard conversations
2. **Advanced Graph**: Extensible graph with custom nodes
3. **Conditional Graph**: Smart routing based on message content
4. **Enhanced Graph**: Full-featured graph with API tools and history management

## Extending the Graph

The system is designed to be easily extensible. To add new nodes to the graph:

1. Define new node functions in `app/graph/nodes.py`
2. Update the graph builder in `app/graph/builder.py` to include your new nodes
3. Modify the API routes as needed to support new functionality

Example of adding a new node:

```python
# In app/graph/nodes.py
async def my_new_node(state: GraphState) -> GraphState:
    # Process state
    return updated_state

# In app/graph/builder.py
async def build_custom_graph(llm: BaseLLM) -> StateGraph:
    # ... existing code ...
    graph.add_node("my_new_node", my_new_node)
    graph.add_edge("generate", "my_new_node")
    graph.add_edge("my_new_node", "postprocess")
    # ... rest of the code ...
```

## Documentation

Comprehensive documentation is available in the `docs/` directory:

- **API Documentation**: Complete API reference with examples
- **Architecture Guide**: Detailed system architecture and design patterns
- **Services Documentation**: In-depth service descriptions and implementations
- **Database Schema**: Database models and relationships
- **LangGraph Architecture**: Graph design patterns and node implementations
- **LangSmith Integration**: Comprehensive guide for tracing, monitoring, debugging, and evaluating LLM applications
- **DeepSeek Integration**: Guide for using DeepSeek models as an alternative LLM provider

## License

MIT